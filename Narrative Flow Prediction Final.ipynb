{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import logging\n",
    "import os.path\n",
    "import sys\n",
    "import gensim\n",
    "import pandas as pd\n",
    "\n",
    "# silience .loc warning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import random\n",
    "# for charts\n",
    "import matplotlib.pyplot as plt\n",
    "# natural language toolkit\n",
    "import nltk\n",
    "# To create Corpus\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# for Topic model\n",
    "from gensim.corpora import Dictionary, HashDictionary, MmCorpus, WikiCorpus\n",
    "from gensim.models import TfidfModel\n",
    "# for cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for NF model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# for confusion matrix\n",
    "from sklearn import metrics\n",
    "# for standard stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# to count repeated words across topics \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_docs(df,col):\n",
    "    # Create LDA from DM\n",
    "    # Split documents\n",
    "    docs_list = df[col].to_list()\n",
    "    texts = [d.split() for d in docs_list]\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(texts)\n",
    "    # Term Document Frequency (corpus)\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    return id2word, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topics(df,col):\n",
    "    list_art = df[col].to_list()\n",
    "    dataset = [d.split() for d in list_art]\n",
    "    art_corpus = [id2word.doc2bow(text) for text in dataset]\n",
    "#     return(art_corpus)\n",
    "\n",
    "    vecs = []\n",
    "    for i in range(len(art_corpus)):\n",
    "        top_topics = (\n",
    "            lda.get_document_topics(art_corpus[i],\n",
    "                                          minimum_probability=0.0)\n",
    "        )\n",
    "        topic_vec = [top_topics[i][1] for i in range(len(top_topics))]\n",
    "#         topic_vec.append(label)\n",
    "        vecs.append(topic_vec)\n",
    "    df = pd.DataFrame(np.row_stack(vecs))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfp(final_topics):\n",
    "    X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "    y = final_topics['label'] # Target variable\n",
    "    # split X and y into training and testing sets\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "    # instantiate the model (using the default parameters)\n",
    "    logreg = LogisticRegression()\n",
    "    # fit the model with data\n",
    "    logreg.fit(X_train,y_train)\n",
    "    # predict y\n",
    "    y_pred=logreg.predict(X_test)\n",
    "    y_pred_train=logreg.predict(X_train)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "    return cnf_matrix, cnf_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(cnf_mtx):\n",
    "    TN = cnf_mtx[0,0]\n",
    "    TP = cnf_mtx[1,1]\n",
    "    FP = cnf_mtx[0,1]\n",
    "    FN = cnf_mtx[1,0]\n",
    "    accuracy = (TP + TN) / (TP+TN+FP+FN)\n",
    "    precision = TP / (TP + FN)\n",
    "    recall = TP / (TP + FP) \n",
    "    return accuracy, precision, recall ,TN, FN, FP, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_articles(df,col):\n",
    "#     cols = ['part1', 'part2']\n",
    "#     lst = []\n",
    "#     art_list = df[col].to_list()\n",
    "# #     art_list = dm['articles'].to_list()\n",
    "#     for a in range(len(df)):\n",
    "#         i = art_list[a]\n",
    "#         length = len(i)\n",
    "#         half = len(i)//2\n",
    "#         part_1 = i[0:half-1]\n",
    "#         part_2 = i[half:length]\n",
    "#         lst.append([part_1, part_2])\n",
    "#     df1 = pd.DataFrame(lst, columns=cols)\n",
    "#     return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_articles(df,col,new_col1,new_col2):\n",
    "    split_list = []\n",
    "    art_list = df[col].to_list()\n",
    "#     art_list = dm['articles'].to_list()\n",
    "    for a in range(len(df)):\n",
    "        i = art_list[a]\n",
    "        half = len(i)//2\n",
    "        part_1 = i[0:half-1]\n",
    "        part_2 = i[half:len(i)]\n",
    "        split_list.append([part_1, part_2])\n",
    "    df1 = pd.DataFrame(split_list, columns=[new_col1,new_col2])\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_pt2(df,col):\n",
    "    df_split = split_articles(df,col,'part1','part2')\n",
    "    bad_df=pd.DataFrame()\n",
    "    bad_df['part2'] = np.random.permutation(df_split['part2'].values)\n",
    "    bad_df['all'] = df_split.part1.str.cat(bad_df.part2)\n",
    "    return bad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_topics(good_df,col1,bad_df, col2):\n",
    "    good_topics = create_topics(good_df,col1)\n",
    "    good_topics['label'] = 1\n",
    "    bad_topics = create_topics(bad_df,col2)\n",
    "    bad_topics['label'] = 0\n",
    "    final_topics = good_topics.append(bad_topics)\n",
    "    return nfp(final_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(corpus,id2word,num_topics,df,col):\n",
    "    lda = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "    split = split_articles(df,col,'part1','part2')\n",
    "    bad_df = rand_pt2(split,'part2')\n",
    "    cnf_matrix, cnf_matrix_train = test_topics(df,col,bad_df,'all')\n",
    "    return lda, num_topics, get_results(cnf_matrix), get_results(cnf_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main_process(corpus,id2word,num_topics):\n",
    "#     lda = gensim.models.LdaMulticore(corpus=corpus,\n",
    "#                                        id2word=id2word,\n",
    "#                                        num_topics=num_topics)\n",
    "#     good_topics = create_topics(dm,'articles')\n",
    "#     good_topics['label'] = 1\n",
    "#     dm_split = split_articles(dm,'articles')\n",
    "#     # Create bad articles by randomising second half\n",
    "#     bad_df =  pd.DataFrame()\n",
    "#     bad_df['part1'] = dm_split['part1']\n",
    "#     bad_df['part2'] = np.random.permutation(dm_split['part2'].values)\n",
    "#     # and merge\n",
    "#     bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "#     bad_topics = create_topics(bad_df,'all')\n",
    "#     bad_topics['label'] = 0\n",
    "#     # Dataset with good and bad articles\n",
    "#     final_topics = good_topics.append(bad_topics)\n",
    "#     # Create NF Model\n",
    "#     X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "#     y = final_topics['label'] # Target variable\n",
    "#     # split X and y into training and testing sets\n",
    "#     X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "#     # instantiate the model (using the default parameters)\n",
    "#     logreg = LogisticRegression()\n",
    "#     # fit the model with data\n",
    "#     logreg.fit(X_train,y_train)\n",
    "#     # predict y\n",
    "#     y_pred=logreg.predict(X_test)\n",
    "#     y_pred_train=logreg.predict(X_train)\n",
    "#     cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "#     cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "\n",
    "# #     Add results for training set\n",
    "#     return lda,   num_topics, get_results(cnf_matrix), get_results(cnf_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_remove_list(t):    \n",
    "    # select topics and their words, includes %\n",
    "    x=lda.show_topics(num_topics=t, num_words=10,formatted=False)\n",
    "    # select only words and save\n",
    "    topics_words = [[wd[0] for wd in tp[1]] for tp in x]\n",
    "    # count number of times word appears\n",
    "    my_counter = Counter()\n",
    "    for word in topics_words:\n",
    "        my_counter.update(word)\n",
    "    # save words where they ap pear 5 or more times\n",
    "    to_remove = Counter({k: c for k, c in my_counter.items() if c >= 5})\n",
    "    # as list\n",
    "    to_remove_list = list(to_remove)\n",
    "    stop_words.extend(to_remove_list)\n",
    "    return to_remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stops(df,col_old):\n",
    "    df['col_new'] = df[col_old]\n",
    "\n",
    "    for stop_word in stop_words:\n",
    "\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        df['col_new'] =df['col_new'].str.replace(regex_stopword, '')\n",
    "    return df['col_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df,col):\n",
    "    # turn into cleaning function\n",
    "    df['Clean_1'] = df[col].str.lower()\n",
    "    df['Clean_1'] = df['Clean_1'].str.replace(\"\\r\", \" \")\n",
    "    df['Clean_1'] = df['Clean_1'].str.replace(\"\\n\", \" \")\n",
    "    df['Clean_1'] = df['Clean_1'].str.replace(\"    \", \" \")\n",
    "    df['Clean_1'] = df['Clean_1'].str.replace('\"', '')\n",
    "    df['Clean_1'] = df['Clean_1'].str.replace(\"\\\\'\", \"\") \n",
    "    df['Clean_1'] = df['Clean_1'].str.replace(\"–\", \" \") \n",
    "    # posessive nouns\n",
    "    df['Clean_1'] = df['Clean_1'].str.replace(\"'s\", \"\")\n",
    "    df['Clean_1'] = df['Clean_1'].str.replace('’', \"\")\n",
    "\n",
    "    punctuation_signs = list(\"?:!.,;/-–\")\n",
    "#     df['Clean_2'] = df['Clean_1']\n",
    "    for punct_sign in punctuation_signs:\n",
    "        df['Clean_1'] = df['Clean_1'].str.replace(punct_sign, '')\n",
    "    return df['Clean_1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm(df,col):\n",
    "    # TURN INTO FUNCTION\n",
    "    # lemmatize\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    nrows = len(dm)\n",
    "    lemmatized_text_list = []\n",
    "    for row in range(0, nrows):\n",
    "            # Create an empty list containing lemmatized words\n",
    "            lemmatized_list = []\n",
    "            # Save the text and its words into an object\n",
    "            text = df.loc[row][col]\n",
    "            text_words = text.split(\" \")\n",
    "            # Iterate through every word to lemmatize\n",
    "            for word in text_words:\n",
    "                lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "            # Join the list\n",
    "            lemmatized_text = \" \".join(lemmatized_list)\n",
    "            # Append to the list containing the texts\n",
    "            lemmatized_text_list.append(lemmatized_text)\n",
    "\n",
    "    return lemmatized_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/Users/sarahbloomfield/Desktop/MSc Comp Sci/Project/Wiki/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki LDA\n",
    "wiki_lda = gensim.models.ldamodel.LdaModel.load(folder+'lda.model')\n",
    "wiki_id2word = gensim.corpora.Dictionary.load_from_text(folder+'test_long_wordids.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = pd.read_csv('dm_20211205_10294.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word, corpus = create_docs(dm,'articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean unwanted text\n",
    "dm['Clean_2'] = clean(dm,'articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize \n",
    "dm['Clean_3'] = lemm(dm,'Clean_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stop_words = list(stopwords.words('english'))\n",
    "dm['Clean_4'] = remove_stops(dm,'Clean_3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove extendedstopwords\n",
    "# stop_words_extended = pd.read_csv('stop_words.csv')\n",
    "# stop_words = list(stop_words_extended['0'])\n",
    "# dm['Clean_4'] = remove_stops(dm,'Clean_3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_extended = pd.read_csv('stop_words.csv')\n",
    "# stop_words_extended['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word, corpus = create_docs(dm,'Clean_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to define lda before running main process\n",
    "lda = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda, num_topics, results, results_train = main(corpus,id2word,10,dm,'Clean_4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(results_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda, num_topics, results, results_train = main_process(corpus,id2word,10)\n",
    "# print(results)\n",
    "# print(results_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Repeat 100 for distribution\n",
    "results_all = []\n",
    "results_train_all = []\n",
    "for i in range (0,10):\n",
    "    print(i)\n",
    "    lda, num_topics, results, results_train = main(corpus,id2word,10,dm,'Clean_4')\n",
    "    results_list = list(results)\n",
    "    results_train_list = list(results_train)\n",
    "    results_train_all.append(results_train_list)\n",
    "    results_all.append(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_initial_df = pd.DataFrame (results_all)\n",
    "# results_initial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_in_tn_df = pd.DataFrame (results_train_all)\n",
    "# results_in_tn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min:', min(results_initial_df[0]))\n",
    "print('max:', max(results_initial_df[0]))\n",
    "print('mean:', sum(results_initial_df[0])/(len(results_initial_df[0])))\n",
    "print('std dev:', np.std(results_initial_df[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min:', min(results_in_tn_df[0]))\n",
    "print('max:', max(results_in_tn_df[0]))\n",
    "print('mean:', sum(results_in_tn_df[0])/(len(results_in_tn_df[0])))\n",
    "print('std dev:' ,np.std(results_in_tn_df[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=results_initial_df[0], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('')\n",
    "# plt.text(23, 45, r'$\\mu=15, b=3$')\n",
    "maxfreq = n.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=results_in_tn_df[0], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('')\n",
    "# plt.text(23, 45, r'$\\mu=15, b=3$')\n",
    "maxfreq = n.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= range(0,len(results_initial_df[0]))\n",
    "\n",
    "y1 = results_initial_df[3]\n",
    "y2 = results_initial_df[4]\n",
    "y3 = results_initial_df[5]\n",
    "y4 = results_initial_df[6]\n",
    "plt.plot(x, y1, label = \"line 1\")\n",
    "plt.plot(x, y2, label = \"line 2\")\n",
    "plt.plot(x, y3, label = \"line 3\")\n",
    "plt.plot(x, y4, label = \"line 4\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [[(np.percentile(results_initial_df[3], 0)),\n",
    "        (np.percentile(results_initial_df[4], 0)), \n",
    "         (np.percentile(results_initial_df[5], 0)), \n",
    "         (np.percentile(results_initial_df[6], 0))],\n",
    "[(np.percentile(results_initial_df[3], 50)),\n",
    "        (np.percentile(results_initial_df[4], 50)), \n",
    "         (np.percentile(results_initial_df[5], 50)), \n",
    "         (np.percentile(results_initial_df[6], 50))],\n",
    "[(np.percentile(results_initial_df[3], 100)),\n",
    "        (np.percentile(results_initial_df[4], 100)), \n",
    "         (np.percentile(results_initial_df[5], 100)), \n",
    "         (np.percentile(results_initial_df[6], 100))]]\n",
    "X = np.arange(4)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(X + 0.00, data[0], color = 'b', width = 0.25)\n",
    "ax.bar(X + 0.25, data[1], color = 'g', width = 0.25)\n",
    "ax.bar(X + 0.50, data[2], color = 'r', width = 0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show topics from final lda model\n",
    "lda.show_topics(num_topics=10, num_words=10,formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import CoherenceModel\n",
    "# coherence_model_lda = CoherenceModel(model=lda, texts=corpus, dictionary=id2word, coherence='c_v')\n",
    "# coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_added = []\n",
    "stop_words_to_remove = []\n",
    "results_stopw = []\n",
    "results_sw_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,2):\n",
    "    print(x)\n",
    "    id2word, corpus = create_docs(dm,'Clean_4')\n",
    "    lda, num_topics, results, results_train = main(corpus,id2word,10,dm,'Clean_4')\n",
    "    to_remove_list = (create_remove_list(10))\n",
    "    print(to_remove_list)\n",
    "    stop_words.extend(to_remove_list)\n",
    "    dm['Clean_4'] = remove_stops(dm,'Clean_4')\n",
    "    stop_words_to_remove.append(to_remove_list)\n",
    "    num_stopw = len(to_remove_list)\n",
    "    print(num_stopw)\n",
    "    stop_words_added.append(num_stopw)\n",
    "    print(results)\n",
    "    results_list = list(results)\n",
    "    results_sw_train_list = list(results_train)\n",
    "    results_stopw.append(results_list)\n",
    "    results_sw_train.append(results_sw_train_list)\n",
    "\n",
    "    if num_stopw == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_added = []\n",
    "# stop_words_to_remove = []\n",
    "# results_stopw = []\n",
    "# results_sw_train = []\n",
    "# for x in range(0,15):\n",
    "#     print(x)\n",
    "#     id2word, corpus = create_docs(dm,'Clean_4')\n",
    "# #     lda, num_topics, results, results_train = main_process(corpus,id2word,10)\n",
    "#     lda = gensim.models.LdaMulticore(corpus=corpus,\n",
    "#                                        id2word=id2word,\n",
    "#                                        num_topics=10)\n",
    "#     print(\"lda complete\")\n",
    "#     good_topics = create_topics(dm,'Clean_4')\n",
    "#     good_topics['label'] = 1\n",
    "#     print(\"good topics made\")\n",
    "#     dm_split = split_articles(dm,'Clean_4')\n",
    "#     # Create bad articles by randomising second half\n",
    "#     bad_df =  pd.DataFrame()\n",
    "#     bad_df['part1'] = dm_split['part1']\n",
    "#     bad_df['part2'] = np.random.permutation(dm_split['part2'].values)\n",
    "#     # and merge\n",
    "#     bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "#     bad_topics = create_topics(bad_df,'all')\n",
    "#     bad_topics['label'] = 0\n",
    "#     print(\"bad topics made\")\n",
    "#     # Dataset with good and bad articles\n",
    "#     final_topics = good_topics.append(bad_topics)\n",
    "#     # Create NF Model\n",
    "#     X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "#     y = final_topics['label'] # Target variable\n",
    "#     # split X and y into training and testing sets\n",
    "#     X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "#     # instantiate the model (using the default parameters)\n",
    "#     logreg = LogisticRegression()\n",
    "#     # fit the model with data\n",
    "#     logreg.fit(X_train,y_train)\n",
    "#     # predict y\n",
    "#     y_pred=logreg.predict(X_test)\n",
    "#     y_pred_train=logreg.predict(X_train)\n",
    "#     cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "#     cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "#     print(\"NF model complete\")\n",
    "\n",
    "#     to_remove_list = (create_remove_list(10))\n",
    "#     print(to_remove_list)\n",
    "#     # stop_words.extend(to_remove_list)\n",
    "#     # dm['Clean_5'] = remove_stops(dm,'Clean_5','Clean_5')\n",
    "#     stop_words.extend(to_remove_list)\n",
    "#     dm['Clean_4'] = remove_stops(dm,'Clean_4')\n",
    "#     stop_words_to_remove.append(to_remove_list)\n",
    "#     num_stopw = len(to_remove_list)\n",
    "#     print(num_stopw)\n",
    "#     stop_words_added.append(num_stopw)\n",
    "#     # topics_tested = []\n",
    "#     # results_all = []\n",
    "#     # topics_tested.append(num_topics)\n",
    "    \n",
    "#     results = get_results(cnf_matrix)\n",
    "#     results_train = get_results(cnf_matrix_train)\n",
    "    \n",
    "#     print(results)\n",
    "#     results_list = list(results)\n",
    "#     results_sw_train_list = list(results_train)\n",
    "# #     results_list\n",
    "\n",
    "#     results_stopw.append(results_list)\n",
    "#     results_sw_train.append(results_sw_train_list)\n",
    "\n",
    "#     if num_stopw == 0:\n",
    "#         break\n",
    "#     # results_df = pd.DataFrame (results_stopw)\n",
    "#     # results_df['topics'] = topics_tested\n",
    "#     # results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop_words_added)\n",
    "print(stop_words_to_remove)\n",
    "print(results_stopw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sw_df = pd.DataFrame (results_stopw)\n",
    "results_sw_df['num_sw'] = stop_words_added\n",
    "# df = pd.DataFrame (products_list, columns = ['product_name'])\n",
    "results_sw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_removed_df = pd.DataFrame (stop_words_to_remove)\n",
    "stopwords_removed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= range(0,len(results_sw_df['num_sw']))\n",
    "y = results_sw_df[0]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= range(0,len(results_sw_df['num_sw']))\n",
    "y1 = results_sw_df[0]\n",
    "\n",
    "y1 = results_sw_df[3]\n",
    "y2 = results_sw_df[4]\n",
    "y3 = results_sw_df[5]\n",
    "y4 = results_sw_df[6]\n",
    "plt.plot(x, y1, label = \"line 1\")\n",
    "plt.plot(x, y2, label = \"line 2\")\n",
    "plt.plot(x, y3, label = \"line 3\")\n",
    "plt.plot(x, y4, label = \"line 4\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.show_topics(num_topics=10, num_words=10,formatted=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_df = pd.DataFrame (stop_words)\n",
    "# stop_words_df.to_csv('stop_words.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_tested = []\n",
    "results_all = []\n",
    "results_train_all = []\n",
    "for t in range(5, 20, 5): \n",
    "    print(t)\n",
    "    lda, num_topics, results, results_train = main(corpus,id2word,t,dm,'Clean_4')\n",
    "    topics_tested.append(num_topics)\n",
    "    results_list = list(results)\n",
    "    results_train_list = list(results_train)\n",
    "    results_train_all.append(results_train_list)\n",
    "    results_all.append(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics_tested = []\n",
    "# results_all = []\n",
    "# results_train_all = []\n",
    "# for t in range(5, 210, 5): \n",
    "#     print(t)\n",
    "#     lda, num_topics, results, results_train = main_process(corpus,id2word,t)\n",
    "#     topics_tested.append(num_topics)\n",
    "#     results_list = list(results)\n",
    "#     results_train_list = list(results_train)\n",
    "#     results_train_all.append(results_train_list)\n",
    "#     results_all.append(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame (results_all)\n",
    "results_df['topics'] = topics_tested\n",
    "# df = pd.DataFrame (products_list, columns = ['product_name'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(results_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= results_df['topics']\n",
    "y = results_df[0]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= results_df['topics']\n",
    "\n",
    "y1 = results_df[3]\n",
    "y2 = results_df[4]\n",
    "y3 = results_df[5]\n",
    "y4 = results_df[6]\n",
    "plt.plot(x, y1, label = \"line 1\")\n",
    "plt.plot(x, y2, label = \"line 2\")\n",
    "plt.plot(x, y3, label = \"line 3\")\n",
    "plt.plot(x, y4, label = \"line 4\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.show_topics(num_topics=205, num_words=10,formatted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing changing LDA source to wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gensim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-468cb21d6e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# wiki LDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'lda.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'test_long_wordids.txt.bz2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gensim' is not defined"
     ]
    }
   ],
   "source": [
    "# wiki LDA\n",
    "lda = gensim.models.ldamodel.LdaModel.load(folder+'lda.model')\n",
    "id2word = gensim.corpora.Dictionary.load_from_text(folder+'test_long_wordids.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(lda.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 10 words from 100 topics\n",
    "lda.show_topics(num_topics=100, num_words=10,formatted=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_train_wiki = []\n",
    "# results_wiki = []\n",
    "# for i in range (0,20):\n",
    "#     print(i)\n",
    "#     lda, num_topics, results, results_train = main_process(corpus,id2word,10)\n",
    "#     results_list = list(results)\n",
    "#     results_train_list = list(results_train)\n",
    "#     results_train_wiki.append(results_train_list)\n",
    "#     results_wiki.append(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_wiki = []\n",
    "results_wiki = []\n",
    "for i in range (0,20):\n",
    "    print(i)\n",
    "#     lda, num_topics, results, results_train = main(corpus,id2word,t)\n",
    "    split = split_articles(dm,'Clean_4','part1','part2')\n",
    "    bad_df = rand_pt2(split,'part2')\n",
    "    cnf_matrix, cnf_matrix_train = test_topics(df,col,bad_df,'all')\n",
    "\n",
    "#     good_topics = create_topics(dm,'articles')\n",
    "#     good_topics['label'] = 1\n",
    "#     print(\"good topics created\")\n",
    "#     dm_split = split_articles(dm,'articles')\n",
    "#     print(\"split articles\")\n",
    "#     # Create bad articles by randomising second half\n",
    "#     bad_df =  pd.DataFrame()\n",
    "#     bad_df['part1'] = dm_split['part1']\n",
    "#     bad_df['part2'] = np.random.permutation(dm_split['part2'].values)\n",
    "#     # and merge\n",
    "#     bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "#     bad_topics = create_topics(bad_df,'all')\n",
    "#     bad_topics['label'] = 0\n",
    "#     print(\"bad topics created\")\n",
    "#     # Dataset with good and bad articles\n",
    "#     final_topics = good_topics.append(bad_topics)\n",
    "#     print(\"final topics merged\")\n",
    "#     # Create NF Model\n",
    "#     X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "#     y = final_topics['label'] # Target variable\n",
    "#     # split X and y into training and testing sets\n",
    "#     X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "#     # instantiate the model (using the default parameters)\n",
    "#     logreg = LogisticRegression()\n",
    "#     print(\"NF model set up\")\n",
    "#     # fit the model with data\n",
    "#     logreg.fit(X_train,y_train)\n",
    "#     print(\"NF model trained\")\n",
    "#     # predict y\n",
    "#     y_pred=logreg.predict(X_test)\n",
    "#     y_pred_train=logreg.predict(X_train)\n",
    "#     cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "#     cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "#     print(\"complete\")\n",
    "    results = get_results(cnf_matrix)\n",
    "    results_train = get_results(cnf_matrix_train)\n",
    "    \n",
    "    results_list = list(results)\n",
    "    results_train_list = list(results_train)\n",
    "    results_train_wiki.append(results_train_list)\n",
    "    results_wiki.append(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_wiki = []\n",
    "results_wiki = []\n",
    "for i in range (0,20):\n",
    "    print(i)\n",
    "\n",
    "    good_topics = create_topics(dm,'articles')\n",
    "    good_topics['label'] = 1\n",
    "    print(\"good topics created\")\n",
    "    dm_split = split_articles(dm,'articles')\n",
    "    print(\"split articles\")\n",
    "    # Create bad articles by randomising second half\n",
    "    bad_df =  pd.DataFrame()\n",
    "    bad_df['part1'] = dm_split['part1']\n",
    "    bad_df['part2'] = np.random.permutation(dm_split['part2'].values)\n",
    "    # and merge\n",
    "    bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "    bad_topics = create_topics(bad_df,'all')\n",
    "    bad_topics['label'] = 0\n",
    "    print(\"bad topics created\")\n",
    "    # Dataset with good and bad articles\n",
    "    final_topics = good_topics.append(bad_topics)\n",
    "    print(\"final topics merged\")\n",
    "    # Create NF Model\n",
    "    X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "    y = final_topics['label'] # Target variable\n",
    "    # split X and y into training and testing sets\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "    # instantiate the model (using the default parameters)\n",
    "    logreg = LogisticRegression()\n",
    "    print(\"NF model set up\")\n",
    "    # fit the model with data\n",
    "    logreg.fit(X_train,y_train)\n",
    "    print(\"NF model trained\")\n",
    "    # predict y\n",
    "    y_pred=logreg.predict(X_test)\n",
    "    y_pred_train=logreg.predict(X_train)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "    print(\"complete\")\n",
    "    results = get_results(cnf_matrix)\n",
    "    results_train = get_results(cnf_matrix_train)\n",
    "    \n",
    "    results_list = list(results)\n",
    "    results_train_list = list(results_train)\n",
    "    results_train_wiki.append(results_train_list)\n",
    "    results_wiki.append(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_2 = get_results(cnf_matrix)\n",
    "# run_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wiki_df = pd.DataFrame (results_wiki)\n",
    "results_wiki_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_wiki_df = pd.DataFrame (results_train_wiki)\n",
    "results_train_wiki_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= range(0,len(results_wiki_df[0]))\n",
    "y = results_wiki_df[0]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min: ',min(results_wiki_df[0]))\n",
    "print('Max: ',max(results_wiki_df[0]))\n",
    "print('Mean: ',sum(results_wiki_df[0])/(len(results_wiki_df[0])))\n",
    "print('Std dev: ',np.std(results_wiki_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.show_topics(num_topics=100, num_words=10,formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=results_wiki_df[0], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('')\n",
    "# plt.text(23, 45, r'$\\mu=15, b=3$')\n",
    "maxfreq = n.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=results_train_wiki_df[0], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('')\n",
    "# plt.text(23, 45, r'$\\mu=15, b=3$')\n",
    "maxfreq = n.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min: ',min(results_train_wiki_df[0]))\n",
    "print('Max: ',max(results_train_wiki_df[0]))\n",
    "print('Mean: ',sum(results_train_wiki_df[0])/(len(results_wiki_df[0])))\n",
    "print('Std dev: ',np.std(results_train_wiki_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_wiki_df[3] 1546\n",
    "# results_wiki_df[4] 1018\n",
    "# results_wiki_df[5] 1333\n",
    "# # results_wiki_df[6] §§§§§§1\n",
    "# results_wiki 0.543229065475034,\n",
    "#   0.5511463844797179,\n",
    "#   0.48393341076267904,\n",
    "training_df  = pd.DataFrame()\n",
    "training_df['y_test'] = y_test\n",
    "\n",
    "training_df['y_pred'] = y_pred\n",
    "training_df\n",
    "# y_pred\n",
    "# y_test\n",
    "# # y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "good_topics.iloc[[6295]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None)\n",
    "bad_topics.iloc[[9586]].T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_topics.iloc[[10291]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "bad_df.iloc[[9586]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= range(0,len(results_wiki_df[0]))\n",
    "\n",
    "y1 = results_wiki_df[3]\n",
    "y2 = results_wiki_df[4]\n",
    "y3 = results_wiki_df[5]\n",
    "y4 = results_wiki_df[6]\n",
    "plt.plot(x, y1, label = \"line 1\")\n",
    "plt.plot(x, y2, label = \"line 2\")\n",
    "plt.plot(x, y3, label = \"line 3\")\n",
    "plt.plot(x, y4, label = \"line 4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [[(np.percentile(results_wiki_df[3], 0)),\n",
    "        (np.percentile(results_wiki_df[4], 0)), \n",
    "         (np.percentile(results_wiki_df[5], 0)), \n",
    "         (np.percentile(results_wiki_df[6], 0))],\n",
    "[(np.percentile(results_wiki_df[3], 50)),\n",
    "        (np.percentile(results_wiki_df[4], 50)), \n",
    "         (np.percentile(results_wiki_df[5], 50)), \n",
    "         (np.percentile(results_wiki_df[6], 50))],\n",
    "[(np.percentile(results_wiki_df[3], 100)),\n",
    "        (np.percentile(results_wiki_df[4], 100)), \n",
    "         (np.percentile(results_wiki_df[5], 100)), \n",
    "         (np.percentile(results_wiki_df[6], 100))]]\n",
    "X = np.arange(4)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(X + 0.00, data[0], color = 'b', width = 0.25)\n",
    "ax.bar(X + 0.25, data[1], color = 'g', width = 0.25)\n",
    "ax.bar(X + 0.50, data[2], color = 'r', width = 0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_topics.mean(axis=0,index ='label')\n",
    "mean_label = final_topics.groupby('label').mean()\n",
    "mean_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_label.to_csv('mean_label.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_label_T = mean_label.T\n",
    "mean_label_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= range(0,len(mean_label_T[0]))\n",
    "\n",
    "y1 = mean_label_T[0]\n",
    "y2 = mean_label_T[1]\n",
    "plt.plot(x, y1, label = \"line 1\")\n",
    "plt.plot(x, y2, label = \"line 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "  \n",
    "# kmeans = KMeans(n_clusters=3).fit(bad_topics)\n",
    "# centroids = kmeans.cluster_centers_\n",
    "# print(centroids)\n",
    "\n",
    "# plt.scatter(bad_topics[10], bad_topics[13], c= kmeans.labels_.astype(float), s=50, alpha=0.5)\n",
    "# plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.percentile(mean_label_T[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_topics\n",
    "# final_topics.loc[final_topics['label'] == 1]\n",
    "# bad_sample = bad_topics.sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_topics\n",
    "bins = [0, .20, .40, .60, .80, 1.00]\n",
    "bad_topics['bin10'] = pd.cut(bad_topics[10], bins)\n",
    "bad_topics['bin13'] = pd.cut(bad_topics[13], bins)\n",
    "bad_topics['bin84'] = pd.cut(bad_topics[84], bins)\n",
    "bad_topics['bin9'] = pd.cut(bad_topics[9], bins)\n",
    "bad_topics['bin23'] = pd.cut(bad_topics[23], bins)\n",
    "bad_topics['bin58'] = pd.cut(bad_topics[58], bins)\n",
    "good_topics['bin10'] = pd.cut(good_topics[10], bins)\n",
    "good_topics['bin13'] = pd.cut(good_topics[13], bins)\n",
    "good_topics['bin84'] = pd.cut(good_topics[84], bins)\n",
    "good_topics['bin9'] = pd.cut(good_topics[9], bins)\n",
    "good_topics['bin23'] = pd.cut(good_topics[23], bins)\n",
    "good_topics['bin58'] = pd.cut(good_topics[58], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bin_df = pd.DataFrame()\n",
    "good_bin_df['g_bin10'] = good_topics['bin10'].value_counts()\n",
    "good_bin_df['g_bin13'] = good_topics['bin13'].value_counts()\n",
    "good_bin_df['g_bin84'] = good_topics['bin84'].value_counts()\n",
    "good_bin_df['g_bin9'] = good_topics['bin9'].value_counts()\n",
    "good_bin_df['g_bin23'] = good_topics['bin23'].value_counts()\n",
    "good_bin_df['g_bin58'] = good_topics['bin58'].value_counts()\n",
    "good_bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_bin_df = pd.DataFrame()\n",
    "bad_bin_df['bin10'] = bad_topics['bin10'].value_counts()\n",
    "bad_bin_df['bin13'] = bad_topics['bin13'].value_counts()\n",
    "bad_bin_df['bin84'] = bad_topics['bin84'].value_counts()\n",
    "bad_bin_df['bin9'] = bad_topics['bin9'].value_counts()\n",
    "bad_bin_df['bin23'] = bad_topics['bin23'].value_counts()\n",
    "bad_bin_df['bin58'] = bad_topics['bin58'].value_counts()\n",
    "bad_bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_topics['bin10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_topics['bin13'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_topics['bin84'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good_topics['bin10'].value_counts())\n",
    "print(good_topics['bin13'].value_counts())\n",
    "print(good_topics['bin84'].value_counts())\n",
    "# print(good_topics['bin9'].value_counts())\n",
    "# print(good_topics['bin23'].value_counts())\n",
    "# print(good_topics['bin58'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = pd.DataFrame()\n",
    "bin_df['g_bin10'] = good_topics['bin10'].value_counts()\n",
    "bin_df['g_bin13'] = good_topics['bin13'].value_counts()\n",
    "bin_df['g_bin84'] = good_topics['bin84'].value_counts()\n",
    "bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sample = good_topics.sample(n=100, random_state=1)\n",
    "good_sample = good_sample[[10, 13,84,9,23,58]]\n",
    "sns.heatmap(good_sample, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sample = bad_sample[[10, 13,84,9,23,58]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(bad_sample, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mport numpy as np \n",
    "# from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "Index= ['aaa', 'bbb', 'ccc', 'ddd', 'eee']\n",
    "Cols = ['A', 'B', 'C', 'D']\n",
    "df = pd.DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)\n",
    "\n",
    "sns.heatmap(df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[(np.percentile(mean_label_T[0], 0)),\n",
    "        (np.percentile(mean_label_T[1], 0))],\n",
    "[(np.percentile(mean_label_T[0], 50)),\n",
    "        (np.percentile(mean_label_T[1], 50))],\n",
    "[(np.percentile(mean_label_T[0], 100)),\n",
    "        (np.percentile(mean_label_T[1], 100))]]\n",
    "X = np.arange(2)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(X + 0.00, data[0], color = 'b', width = 0.25)\n",
    "ax.bar(X + 0.25, data[1], color = 'g', width = 0.25)\n",
    "ax.bar(X + 0.50, data[2], color = 'r', width = 0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test different article lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm['art_len']  = dm['articles'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(dm['art_len'], 0))\n",
    "print(np.percentile(dm['art_len'], 25))\n",
    "print(np.percentile(dm['art_len'], 50))\n",
    "print(np.percentile(dm['art_len'], 75))\n",
    "print(np.percentile(dm['art_len'], 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "73144/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=dm['art_len'], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Article Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('')\n",
    "# plt.text(23, 45, r'$\\mu=15, b=3$')\n",
    "maxfreq = n.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fil_len (df, mini, maxi):\n",
    "    df.loc[df['art_len'] <= maxi, 'not_long'] = 1  \n",
    "    df.loc[df['art_len'] > maxi, 'not_long'] = 0  \n",
    "    df.loc[df['art_len'] < mini, 'not_short'] = 0  \n",
    "    df.loc[df['art_len'] >= mini, 'not_short'] = 1  \n",
    "    df.loc[df['not_long'] + dm['not_short'] ==2 , 'good_len'] = 1\n",
    "    df.loc[df['not_long'] + dm['not_short'] !=2 , 'good_len'] = 0\n",
    "    df = df.loc[df['good_len'] ==1]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_ln = dm\n",
    "dm_ln = fil_len(dm, 1500,30000)\n",
    "print(len(dm_ln))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ln = [2100, 2000, 1900, 1800, 1700, 1600, 1500,   1400,  1300,  1200,  1100  ,1000,  900,   800,   700   ,600   ,500   ,400   ,300   ,200    ,100  ,0]\n",
    "max_ln = [5000, 6000, 7000, 8000, 9000, 10000, 15000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 80000, 80000, 80000, 80000, 80000, 80000, 80000, 80000]\n",
    "test_len = pd.DataFrame()\n",
    "test_len['min_ln'] = min_ln\n",
    "test_len['max_ln'] = max_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_art = []\n",
    "\n",
    "for i in range(len(test_len)):\n",
    "    min_i = test_len.loc[i,'min_ln'] \n",
    "    max_i = test_len.loc[i,'max_ln'] \n",
    "    dm_ln = fil_len(dm,min_i,max_i)\n",
    "    num_art_i = len(dm_ln)\n",
    "    num_art.append(num_art_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len['num_art']=num_art\n",
    "test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_ln = fil_len(dm, 5000,10000)\n",
    "print(len(dm_ln))\n",
    "dm_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_added = []\n",
    "# stop_words_to_remove = []\n",
    "results_ln = []\n",
    "for i in range(len(test_len)):\n",
    "    print (i)\n",
    "    min_i = test_len.loc[i,'min_ln'] \n",
    "    max_i = test_len.loc[i,'max_ln'] \n",
    "    dm_ln = fil_len(dm, min_i,max_i)\n",
    "    good_topics = create_topics(dm_ln,'articles')\n",
    "    good_topics['label'] = 1\n",
    "    print(\"good topics created\")\n",
    "    dm_split = split_articles(dm_ln,'articles')\n",
    "    print(\"split articles\")\n",
    "    # Create bad articles by randomising second half\n",
    "    bad_df =  pd.DataFrame()\n",
    "    bad_df['part1'] = dm_split['part1']\n",
    "    bad_df['part2'] = np.random.permutation(dm_split['part2'].values)\n",
    "    # and merge\n",
    "    bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "    bad_topics = create_topics(bad_df,'all')\n",
    "    bad_topics['label'] = 0\n",
    "    print(\"bad topics created\")\n",
    "    # Dataset with good and bad articles\n",
    "    final_topics = good_topics.append(bad_topics)\n",
    "    print(\"final topics merged\")\n",
    "    # Create NF Model\n",
    "    X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "    y = final_topics['label'] # Target variable\n",
    "    # split X and y into training and testing sets\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "    # instantiate the model (using the default parameters)\n",
    "    logreg = LogisticRegression()\n",
    "    print(\"NF model set up\")\n",
    "    # fit the model with data\n",
    "    logreg.fit(X_train,y_train)\n",
    "    print(\"NF model trained\")\n",
    "    # predict y\n",
    "    y_pred=logreg.predict(X_test)\n",
    "    y_train_pred=logreg.predict(X_train)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    results = get_results(cnf_matrix)\n",
    "    results_ln.append(results)\n",
    "    print(\"complete\")\n",
    "    print(min_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ln_df = pd.DataFrame (results_ln)\n",
    "results_ln_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= range(0,22)\n",
    "y = results_ln_df[0]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len['num_art'] = num_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len['accuracy']= results_ln_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_len = test_len.join(results_ln_df) \n",
    "# test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x= test_len['num_art']\n",
    "# y = test_len[0]\n",
    "\n",
    "# plt.plot(x, y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_len_list = dm_ln['articles'].to_list()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6.5 Test article length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the impact of sample size on modelling performance, a random sample of x documents were taken from the corpus, where x was 5,000 to 10,000 increasing in chunks of 500. In keeping with the overall methodology, those articles were then turned into poor articles by randomising the second half of the article, therefore the model is fed 10,000 to 20,000 examples. Testing whether the model seeing half of the poor article previously is a separate test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_sz = []\n",
    "for i in range (1000,20010,10):\n",
    "    smp_sz.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smp_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.sample(final_topics[0], 5)\n",
    "# df = final_topics.sample(5)\n",
    "results_ss = []\n",
    "for i in smp_sz:\n",
    "    print(i)\n",
    "    sample_topics = final_topics.sample(i)\n",
    "    X = sample_topics.loc[:,sample_topics.columns != 'label']\n",
    "    y = sample_topics['label'] # Target variable\n",
    "    # split X and y into training and testing sets\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "    # instantiate the model (using the default parameters)\n",
    "    logreg = LogisticRegression()\n",
    "    print(\"NF model set up\")\n",
    "    # fit the model with data\n",
    "    logreg.fit(X_train,y_train)\n",
    "    print(\"NF model trained\")\n",
    "    # predict y\n",
    "    y_pred=logreg.predict(X_test)\n",
    "    y_train_pred=logreg.predict(X_train)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    results = get_results(cnf_matrix)\n",
    "    results_ss.append(results)\n",
    "    print(\"complete\")\n",
    "#     print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ss_df = pd.DataFrame (results_ss)\n",
    "results_ss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= smp_sz\n",
    "y = results_ss_df[0]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6.6 Break article into chunks of 2, 4, 6, 8, 10 and run topic model on each chunk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of taking the full topic model, it is possible to break the article into smaller chunks and run the topic model on each section. The number of parameters, k, increases to s x t, where s is the number of sections and t the number of topics. \n",
    "To create the poor article, good articles are already split into two sections. Once poor articles are created the halfway point will be in a different place to the original split, as article lengths differ. However, to increase the chance of the model finding a narrative break, the split remains at the original position. The two sections (s = 2) are placed into the topic model separately for the topic distributions.\n",
    "The two sections are then split further, so that s = 4, 6, 8, 10. The only randomisation is occurs when creating the poor articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm['articles']\n",
    "dm_ln = fil_len(dm, 1000,60000)\n",
    "dm_ln['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_split = split_articles(dm_ln,'articles')\n",
    "good_top_pt1 = create_topics(dm_split,'part1')\n",
    "good_top_pt2 = create_topics(dm_split,'part2')\n",
    "good_topics = pd.concat([good_top_pt1, good_top_pt2], axis=1)\n",
    "# good_topics = create_topics(dm_ln,'articles')\n",
    "good_topics['label'] = 1\n",
    "print(\"good topics created\")\n",
    "bad_pt2 = good_top_pt2.sample(frac = 1).reset_index(drop=True)\n",
    "bad_top_all = pd.concat([good_top_pt1, bad_pt2], axis=1)\n",
    "bad_top_all['label'] = 0\n",
    "print(\"bad topics created\")\n",
    "# Dataset with good and bad articles\n",
    "final_topics = good_topics.append(bad_top_all)\n",
    "print(\"final topics merged\")\n",
    "# Create NF Model\n",
    "X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "y = final_topics['label'] # Target variable\n",
    "# split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "print(\"NF model set up\")\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "print(\"NF model trained\")\n",
    "# predict y\n",
    "y_pred=logreg.predict(X_test)\n",
    "y_pred_train=logreg.predict(X_train)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "results_spl2 = get_results(cnf_matrix)\n",
    "results_train_spl2 = get_results(cnf_matrix_train)\n",
    "# results_ss.append(results)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_spl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_spl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_articles_4(df,col):\n",
    "    cols = ['part1', 'part2', 'part3', 'part4']\n",
    "    lst = []\n",
    "    art_list = df[col].to_list()\n",
    "    for a in range(len(df)):\n",
    "        i = art_list[a]\n",
    "        length = len(i)\n",
    "        qtr = len(i)//6\n",
    "        part_1 = i[0:qtr-1]\n",
    "        part_2 = i[0+qtr:2*qtr-1]\n",
    "        part_3 = i[0+2*qtr:3*qtr-1]\n",
    "        part_4 = i[0+3*qtr:length]\n",
    "        lst.append([part_1, part_2, part_3, part_4])\n",
    "    df1 = pd.DataFrame(lst, columns=cols)\n",
    "    return df1\n",
    "\n",
    "dm_split = split_articles_4(dm,'articles')\n",
    "\n",
    "top_pt1 = create_topics(dm_split,'part1')\n",
    "top_pt2 = create_topics(dm_split,'part2')\n",
    "top_pt3 = create_topics(dm_split,'part3')\n",
    "top_pt4 = create_topics(dm_split,'part4')\n",
    "print(type(top_pt4))\n",
    "good_topics = pd.concat([top_pt1, top_pt2, top_pt3, top_pt4], axis=1)\n",
    "# good_topics = create_topics(dm_ln,'articles')\n",
    "good_topics['label'] = 1\n",
    "print(\"good topics created\")\n",
    "# dm_split = split_articles(dm_ln,'articles')\n",
    "# print(\"split articles\")\n",
    "# Create bad articles by randomising second half\n",
    "# bad_df =  pd.DataFrame()\n",
    "# bad_df['part1'] = dm_split['part1']\n",
    "bad_pt3 = top_pt3.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt4 = top_pt4.sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "# bad_pt3 = np.random.permutation(top_pt3)\n",
    "# bad_pt4 = np.random.permutation(top_pt4)\n",
    "print(type(bad_pt3))\n",
    "# and merge\n",
    "# bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "# bad_top_pt1 = create_topics(bad_df,'part1')\n",
    "# bad_top_pt2 = create_topics(bad_df,'part2')\n",
    "bad_topics = pd.concat([top_pt1, top_pt2, bad_pt3,bad_pt4], axis=1)\n",
    "bad_topics['label'] = 0\n",
    "print(\"bad topics created\")\n",
    "# Dataset with good and bad articles\n",
    "final_topics = good_topics.append(bad_topics)\n",
    "print(\"final topics merged\")\n",
    "# Create NF Model\n",
    "X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "y = final_topics['label'] # Target variable\n",
    "# split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "print(\"NF model set up\")\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "print(\"NF model trained\")\n",
    "# predict y\n",
    "y_pred=logreg.predict(X_test)\n",
    "y_pred_train=logreg.predict(X_train)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "results_spl4 = get_results(cnf_matrix)\n",
    "results_train_spl4 = get_results(cnf_matrix_train)\n",
    "# results_ss.append(results)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_spl4)\n",
    "print(results_train_spl4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_articles_6(df,col):\n",
    "    cols = ['part1', 'part2', 'part3', 'part4', 'part5', 'part6']\n",
    "    lst = []\n",
    "    art_list = df[col].to_list()\n",
    "    for a in range(len(df)):\n",
    "        i = art_list[a]\n",
    "        length = len(i)\n",
    "        qtr = len(i)//6\n",
    "        part_1 = i[0:qtr-1]\n",
    "        part_2 = i[0+qtr:2*qtr-1]\n",
    "        part_3 = i[0+2*qtr:3*qtr-1]\n",
    "        part_4 = i[0+3*qtr:4*qtr-1]\n",
    "        part_5 = i[0+4*qtr:5*qtr-1]\n",
    "        part_6 = i[0+5*qtr:length]\n",
    "        lst.append([part_1, part_2, part_3, part_4, part_5, part_6])\n",
    "    df1 = pd.DataFrame(lst, columns=cols)\n",
    "    return df1\n",
    "\n",
    "dm_split = split_articles_6(dm,'articles')\n",
    "\n",
    "top_pt1 = create_topics(dm_split,'part1')\n",
    "top_pt2 = create_topics(dm_split,'part2')\n",
    "top_pt3 = create_topics(dm_split,'part3')\n",
    "top_pt4 = create_topics(dm_split,'part4')\n",
    "top_pt5 = create_topics(dm_split,'part5')\n",
    "top_pt6 = create_topics(dm_split,'part6')\n",
    "print(type(top_pt4))\n",
    "good_topics = pd.concat([top_pt1, top_pt2, top_pt3, top_pt4, top_pt5, top_pt6], axis=1)\n",
    "# good_topics = create_topics(dm_ln,'articles')\n",
    "good_topics['label'] = 1\n",
    "print(\"good topics created\")\n",
    "# dm_split = split_articles(dm_ln,'articles')\n",
    "# print(\"split articles\")\n",
    "# Create bad articles by randomising second half\n",
    "# bad_df =  pd.DataFrame()\n",
    "# bad_df['part1'] = dm_split['part1']\n",
    "bad_pt4 = top_pt4.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt5 = top_pt5.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt6 = top_pt6.sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "# bad_pt3 = np.random.permutation(top_pt3)\n",
    "# bad_pt4 = np.random.permutation(top_pt4)\n",
    "# print(type(bad_pt3))\n",
    "# and merge\n",
    "# bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "# bad_top_pt1 = create_topics(bad_df,'part1')\n",
    "# bad_top_pt2 = create_topics(bad_df,'part2')\n",
    "bad_topics = pd.concat([top_pt1, top_pt2, top_pt3, bad_pt4,bad_pt5,bad_pt6], axis=1)\n",
    "bad_topics['label'] = 0\n",
    "print(\"bad topics created\")\n",
    "# Dataset with good and bad articles\n",
    "final_topics = good_topics.append(bad_topics)\n",
    "print(\"final topics merged\")\n",
    "# Create NF Model\n",
    "X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "y = final_topics['label'] # Target variable\n",
    "# split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "print(\"NF model set up\")\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "print(\"NF model trained\")\n",
    "# predict y\n",
    "y_pred=logreg.predict(X_test)\n",
    "y_pred_train=logreg.predict(X_train)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "results_spl6 = get_results(cnf_matrix)\n",
    "results_train_spl6 = get_results(cnf_matrix_train)\n",
    "# results_ss.append(results)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_spl6)\n",
    "print(results_train_spl6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_articles_8(df,col):\n",
    "    cols = ['part1', 'part2', 'part3', 'part4', 'part5', 'part6', 'part7', 'part8']\n",
    "    lst = []\n",
    "    art_list = df[col].to_list()\n",
    "    for a in range(len(df)):\n",
    "        i = art_list[a]\n",
    "        length = len(i)\n",
    "        qtr = len(i)//8\n",
    "        part_1 = i[0:qtr-1]\n",
    "        part_2 = i[0+qtr:2*qtr-1]\n",
    "        part_3 = i[0+2*qtr:3*qtr-1]\n",
    "        part_4 = i[0+3*qtr:4*qtr-1]\n",
    "        part_5 = i[0+4*qtr:5*qtr-1]\n",
    "        part_6 = i[0+5*qtr:6*qtr-1]\n",
    "        part_7 = i[0+6*qtr:7*qtr-1]\n",
    "        part_8 = i[0+7*qtr:length]\n",
    "        lst.append([part_1, part_2, part_3, part_4, part_5, part_6, part_7, part_8])\n",
    "    df1 = pd.DataFrame(lst, columns=cols)\n",
    "    return df1\n",
    "\n",
    "dm_split = split_articles_8(dm,'articles')\n",
    "\n",
    "top_pt1 = create_topics(dm_split,'part1')\n",
    "top_pt2 = create_topics(dm_split,'part2')\n",
    "top_pt3 = create_topics(dm_split,'part3')\n",
    "top_pt4 = create_topics(dm_split,'part4')\n",
    "top_pt5 = create_topics(dm_split,'part5')\n",
    "top_pt6 = create_topics(dm_split,'part6')\n",
    "top_pt7 = create_topics(dm_split,'part7')\n",
    "top_pt8 = create_topics(dm_split,'part8')\n",
    "good_topics = pd.concat([top_pt1, top_pt2, top_pt3, top_pt4, top_pt5, top_pt6, top_pt7, top_pt8], axis=1)\n",
    "# good_topics = create_topics(dm_ln,'articles')\n",
    "good_topics['label'] = 1\n",
    "print(\"good topics created\")\n",
    "# dm_split = split_articles(dm_ln,'articles')\n",
    "# print(\"split articles\")\n",
    "# Create bad articles by randomising second half\n",
    "# bad_df =  pd.DataFrame()\n",
    "# bad_df['part1'] = dm_split['part1']\n",
    "bad_pt5 = top_pt5.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt6 = top_pt6.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt7 = top_pt7.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt8 = top_pt8.sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "# bad_pt3 = np.random.permutation(top_pt3)\n",
    "# bad_pt4 = np.random.permutation(top_pt4)\n",
    "# print(type(bad_pt3))\n",
    "# and merge\n",
    "# bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "# bad_top_pt1 = create_topics(bad_df,'part1')\n",
    "# bad_top_pt2 = create_topics(bad_df,'part2')\n",
    "bad_topics = pd.concat([top_pt1, top_pt2, top_pt3, top_pt4,bad_pt5,bad_pt6,bad_pt7,bad_pt8], axis=1)\n",
    "bad_topics['label'] = 0\n",
    "print(\"bad topics created\")\n",
    "# Dataset with good and bad articles\n",
    "final_topics = good_topics.append(bad_topics)\n",
    "print(\"final topics merged\")\n",
    "# Create NF Model\n",
    "X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "y = final_topics['label'] # Target variable\n",
    "# split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "print(\"NF model set up\")\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "print(\"NF model trained\")\n",
    "# predict y\n",
    "y_pred=logreg.predict(X_test)\n",
    "y_pred_train=logreg.predict(X_train)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "results_spl8 = get_results(cnf_matrix)\n",
    "results_train_spl8 = get_results(cnf_matrix_train)\n",
    "# results_ss.append(results)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_spl8)\n",
    "print(results_train_spl8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_articles_10(df,col):\n",
    "    cols = ['part1', 'part2', 'part3', 'part4', 'part5', 'part6', 'part7', 'part8', 'part9', 'part10']\n",
    "    lst = []\n",
    "    art_list = df[col].to_list()\n",
    "    for a in range(len(df)):\n",
    "        i = art_list[a]\n",
    "        length = len(i)\n",
    "        qtr = len(i)//8\n",
    "        part_1 = i[0:qtr-1]\n",
    "        part_2 = i[0+qtr:2*qtr-1]\n",
    "        part_3 = i[0+2*qtr:3*qtr-1]\n",
    "        part_4 = i[0+3*qtr:4*qtr-1]\n",
    "        part_5 = i[0+4*qtr:5*qtr-1]\n",
    "        part_6 = i[0+5*qtr:6*qtr-1]\n",
    "        part_7 = i[0+6*qtr:7*qtr-1]\n",
    "        part_8 = i[0+7*qtr:8*qtr-1]\n",
    "        part_9 = i[0+8*qtr:9*qtr-1]\n",
    "        part_10 = i[0+9*qtr:length]\n",
    "        lst.append([part_1, part_2, part_3, part_4, part_5, part_6, part_7, part_8, part_9, part_10])\n",
    "    df1 = pd.DataFrame(lst, columns=cols)\n",
    "    return df1\n",
    "\n",
    "dm_split = split_articles_10(dm,'articles')\n",
    "\n",
    "top_pt1 = create_topics(dm_split,'part1')\n",
    "top_pt2 = create_topics(dm_split,'part2')\n",
    "top_pt3 = create_topics(dm_split,'part3')\n",
    "top_pt4 = create_topics(dm_split,'part4')\n",
    "top_pt5 = create_topics(dm_split,'part5')\n",
    "top_pt6 = create_topics(dm_split,'part6')\n",
    "top_pt7 = create_topics(dm_split,'part7')\n",
    "top_pt8 = create_topics(dm_split,'part8')\n",
    "top_pt9 = create_topics(dm_split,'part9')\n",
    "top_pt10 = create_topics(dm_split,'part10')\n",
    "\n",
    "good_topics = pd.concat([top_pt1, top_pt2, top_pt3, top_pt4, top_pt5, top_pt6, top_pt7, top_pt8, top_pt9, top_pt10], axis=1)\n",
    "# good_topics = create_topics(dm_ln,'articles')\n",
    "good_topics['label'] = 1\n",
    "print(\"good topics created\")\n",
    "# dm_split = split_articles(dm_ln,'articles')\n",
    "# print(\"split articles\")\n",
    "# Create bad articles by randomising second half\n",
    "# bad_df =  pd.DataFrame()\n",
    "# bad_df['part1'] = dm_split['part1']\n",
    "bad_pt6 = top_pt6.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt7 = top_pt7.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt8 = top_pt8.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt9 = top_pt9.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt10 = top_pt10.sample(frac = 1).reset_index(drop=True)\n",
    "# bad_pt3 = np.random.permutation(top_pt3)\n",
    "# bad_pt4 = np.random.permutation(top_pt4)\n",
    "# print(type(bad_pt3))\n",
    "# and merge\n",
    "# bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "# bad_top_pt1 = create_topics(bad_df,'part1')\n",
    "# bad_top_pt2 = create_topics(bad_df,'part2')\n",
    "bad_topics = pd.concat([top_pt1, top_pt2, top_pt3, top_pt4,top_pt5,bad_pt6,bad_pt7,bad_pt8,bad_pt9,bad_pt10], axis=1)\n",
    "bad_topics['label'] = 0\n",
    "print(\"bad topics created\")\n",
    "# Dataset with good and bad articles\n",
    "final_topics = good_topics.append(bad_topics)\n",
    "print(\"final topics merged\")\n",
    "# Create NF Model\n",
    "X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "y = final_topics['label'] # Target variable\n",
    "# split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "print(\"NF model set up\")\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "print(\"NF model trained\")\n",
    "# predict y\n",
    "y_pred=logreg.predict(X_test)\n",
    "y_pred_train=logreg.predict(X_train)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "results_spl10 = get_results(cnf_matrix)\n",
    "results_train_spl10 = get_results(cnf_matrix_train)\n",
    "\n",
    "# results_ss.append(results)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_spl10)\n",
    "print(results_train_spl10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_articles_12(df,col):\n",
    "    cols = ['part1', 'part2', 'part3', 'part4', 'part5', 'part6'\n",
    "            , 'part7', 'part8', 'part9', 'part10', 'part11', 'part12']\n",
    "    lst = []\n",
    "    art_list = df[col].to_list()\n",
    "    for a in range(len(df)):\n",
    "        i = art_list[a]\n",
    "        length = len(i)\n",
    "        qtr = len(i)//8\n",
    "        part_1 = i[0:qtr-1]\n",
    "        part_2 = i[0+qtr:2*qtr-1]\n",
    "        part_3 = i[0+2*qtr:3*qtr-1]\n",
    "        part_4 = i[0+3*qtr:4*qtr-1]\n",
    "        part_5 = i[0+4*qtr:5*qtr-1]\n",
    "        part_6 = i[0+5*qtr:6*qtr-1]\n",
    "        part_7 = i[0+6*qtr:7*qtr-1]\n",
    "        part_8 = i[0+7*qtr:8*qtr-1]\n",
    "        part_9 = i[0+8*qtr:9*qtr-1]\n",
    "        part_10 = i[0+9*qtr:10*qtr-1]\n",
    "        part_11 = i[0+10*qtr:11*qtr-1]\n",
    "        part_12 = i[0+11*qtr:length]\n",
    "        lst.append([part_1, part_2, part_3, part_4, part_5, part_6\n",
    "                    , part_7, part_8, part_9, part_10, part_11, part_12])\n",
    "    df1 = pd.DataFrame(lst, columns=cols)\n",
    "    return df1\n",
    "\n",
    "dm_split = split_articles_12(dm,'articles')\n",
    "\n",
    "top_pt1 = create_topics(dm_split,'part1')\n",
    "top_pt2 = create_topics(dm_split,'part2')\n",
    "top_pt3 = create_topics(dm_split,'part3')\n",
    "top_pt4 = create_topics(dm_split,'part4')\n",
    "top_pt5 = create_topics(dm_split,'part5')\n",
    "top_pt6 = create_topics(dm_split,'part6')\n",
    "top_pt7 = create_topics(dm_split,'part7')\n",
    "top_pt8 = create_topics(dm_split,'part8')\n",
    "top_pt9 = create_topics(dm_split,'part9')\n",
    "top_pt10 = create_topics(dm_split,'part10')\n",
    "top_pt11 = create_topics(dm_split,'part11')\n",
    "top_pt12 = create_topics(dm_split,'part12')\n",
    "\n",
    "good_topics = pd.concat([top_pt1, top_pt2, top_pt3, top_pt4, top_pt5, top_pt6\n",
    "                         , top_pt7, top_pt8, top_pt9, top_pt10, top_pt11, top_pt12], axis=1)\n",
    "# good_topics = create_topics(dm_ln,'articles')\n",
    "good_topics['label'] = 1\n",
    "print(\"good topics created\")\n",
    "# dm_split = split_articles(dm_ln,'articles')\n",
    "# print(\"split articles\")\n",
    "# Create bad articles by randomising second half\n",
    "# bad_df =  pd.DataFrame()\n",
    "# bad_df['part1'] = dm_split['part1']\n",
    "\n",
    "bad_pt7 = top_pt7.sample(frac = 1)\n",
    "bad_pt8 = top_pt8.sample(frac = 1)\n",
    "bad_pt9 = top_pt9.sample(frac = 1)\n",
    "bad_pt10 = top_pt10.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt11 = top_pt11.sample(frac = 1).reset_index(drop=True)\n",
    "bad_pt12 = top_pt12.sample(frac = 1).reset_index(drop=True)\n",
    "# bad_pt3 = np.random.permutation(top_pt3)\n",
    "# bad_pt4 = np.random.permutation(top_pt4)\n",
    "# print(type(bad_pt3))\n",
    "# and merge\n",
    "# bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "# bad_top_pt1 = create_topics(bad_df,'part1')\n",
    "# bad_top_pt2 = create_topics(bad_df,'part2')\n",
    "bad_topics = pd.concat([top_pt1, top_pt2, top_pt3, top_pt4, top_pt5, top_pt6\n",
    "                        ,bad_pt7, bad_pt8, bad_pt9, bad_pt10, bad_pt11, bad_pt12], axis=1)\n",
    "bad_topics['label'] = 0\n",
    "print(\"bad topics created\")\n",
    "# Dataset with good and bad articles\n",
    "final_topics = good_topics.append(bad_topics)\n",
    "print(\"final topics merged\")\n",
    "# Create NF Model\n",
    "X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "y = final_topics['label'] # Target variable\n",
    "# split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "print(\"NF model set up\")\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "print(\"NF model trained\")\n",
    "# predict y\n",
    "y_pred=logreg.predict(X_test)\n",
    "y_pred_train=logreg.predict(X_train)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "results_spl12 = get_results(cnf_matrix)\n",
    "results_train_spl12 = get_results(cnf_matrix_train)\n",
    "\n",
    "# results_ss.append(results)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_spl12)\n",
    "print(results_train_spl12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_splt = [results_spl2,results_spl4,results_spl6,results_spl8,results_spl10,results_spl12]\n",
    "results_splt_train = [results_train_spl2,results_train_spl4,results_train_spl6,results_train_spl8\n",
    "                      ,results_train_spl10,results_train_spl12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_split_df = pd.DataFrame (results_splt)\n",
    "print(results_split_df)\n",
    "results_split_train_df = pd.DataFrame (results_splt_train)\n",
    "print(results_split_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= range(0,6)\n",
    "y1 = results_split_df[0]\n",
    "y2 = results_split_train_df[0]\n",
    "\n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= range(0,6)\n",
    "y1 = results_split_df[3]\n",
    "y2 = results_split_df[4]\n",
    "y3 = results_split_df[5]\n",
    "y4 = results_split_df[6]\n",
    "plt.plot(x, y1, label = \"line 1\")\n",
    "plt.plot(x, y2, label = \"line 2\")\n",
    "plt.plot(x, y3, label = \"line 3\")\n",
    "plt.plot(x, y4, label = \"line 4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6.7 Difference in Topic distributions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The break in a narrative flow may be more easily seen as a change in topic distribution rather than the topic distribution itself. A better parameter could therefore be the difference in topic distribution of the two sections of the model. This can be calculated by breaking the article into two chunks, running the topic model on each, and calculating the difference between topic distributions of two sections. These are the parameters in the narrative flow model. Another advantage of this calculating is that although a matrix of width 2x the number of topics (t), this is summarised into t topics, reducing the chance of spurious parameters.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_split = split_articles(dm,'articles')\n",
    "good_top_pt1 = create_topics(dm_split,'part1')\n",
    "good_top_pt2 = create_topics(dm_split,'part2')\n",
    "good_topics = pd.concat([good_top_pt1, good_top_pt2], axis=1)\n",
    "# good_topics = create_topics(dm_ln,'articles')\n",
    "good_topics['label'] = 1\n",
    "print(\"good topics created\")\n",
    "# dm_split = split_articles(dm_ln,'articles')\n",
    "# print(\"split articles\")\n",
    "# Create bad articles by randomising second half\n",
    "\n",
    "# bad_df =  pd.DataFrame()\n",
    "# bad_df['part1'] = dm_split['part1']\n",
    "\n",
    "bad_pt2 = good_top_pt2.sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "bad_top_all = pd.concat([good_top_pt1, bad_pt2], axis=1)\n",
    "bad_top_all['label'] = 0\n",
    "print(\"bad topics created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_top_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_split_df = good_topics.append(bad_top_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_diff = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_diff['0'] = all_split_df.iloc[:,0]-all_split_df.iloc[:,100]\n",
    "topic_diff['1'] = all_split_df.iloc[:,1]-all_split_df.iloc[:,101]\n",
    "topic_diff['2'] = all_split_df.iloc[:,2]-all_split_df.iloc[:,102]\n",
    "topic_diff['3'] = all_split_df.iloc[:,3]-all_split_df.iloc[:,103]\n",
    "topic_diff['4'] = all_split_df.iloc[:,4]-all_split_df.iloc[:,104]\n",
    "topic_diff['5'] = all_split_df.iloc[:,5]-all_split_df.iloc[:,105]\n",
    "topic_diff['6'] = all_split_df.iloc[:,6]-all_split_df.iloc[:,106]\n",
    "topic_diff['7'] = all_split_df.iloc[:,7]-all_split_df.iloc[:,107]\n",
    "topic_diff['8'] = all_split_df.iloc[:,8]-all_split_df.iloc[:,108]\n",
    "topic_diff['9'] = all_split_df.iloc[:,9]-all_split_df.iloc[:,109]\n",
    "topic_diff['10'] = all_split_df.iloc[:,10]-all_split_df.iloc[:,110]\n",
    "topic_diff['11'] = all_split_df.iloc[:,11]-all_split_df.iloc[:,111]\n",
    "topic_diff['12'] = all_split_df.iloc[:,12]-all_split_df.iloc[:,112]\n",
    "topic_diff['13'] = all_split_df.iloc[:,13]-all_split_df.iloc[:,113]\n",
    "topic_diff['14'] = all_split_df.iloc[:,14]-all_split_df.iloc[:,114]\n",
    "topic_diff['15'] = all_split_df.iloc[:,15]-all_split_df.iloc[:,115]\n",
    "topic_diff['16'] = all_split_df.iloc[:,16]-all_split_df.iloc[:,116]\n",
    "topic_diff['17'] = all_split_df.iloc[:,17]-all_split_df.iloc[:,117]\n",
    "topic_diff['18'] = all_split_df.iloc[:,18]-all_split_df.iloc[:,118]\n",
    "topic_diff['19'] = all_split_df.iloc[:,19]-all_split_df.iloc[:,119]\n",
    "topic_diff['20'] = all_split_df.iloc[:,20]-all_split_df.iloc[:,120]\n",
    "topic_diff['21'] = all_split_df.iloc[:,21]-all_split_df.iloc[:,121]\n",
    "topic_diff['22'] = all_split_df.iloc[:,22]-all_split_df.iloc[:,122]\n",
    "topic_diff['23'] = all_split_df.iloc[:,23]-all_split_df.iloc[:,123]\n",
    "topic_diff['24'] = all_split_df.iloc[:,24]-all_split_df.iloc[:,124]\n",
    "topic_diff['25'] = all_split_df.iloc[:,25]-all_split_df.iloc[:,125]\n",
    "topic_diff['26'] = all_split_df.iloc[:,26]-all_split_df.iloc[:,126]\n",
    "topic_diff['27'] = all_split_df.iloc[:,27]-all_split_df.iloc[:,127]\n",
    "topic_diff['28'] = all_split_df.iloc[:,28]-all_split_df.iloc[:,128]\n",
    "topic_diff['29'] = all_split_df.iloc[:,29]-all_split_df.iloc[:,129]\n",
    "topic_diff['30'] = all_split_df.iloc[:,30]-all_split_df.iloc[:,130]\n",
    "topic_diff['31'] = all_split_df.iloc[:,31]-all_split_df.iloc[:,131]\n",
    "topic_diff['32'] = all_split_df.iloc[:,32]-all_split_df.iloc[:,132]\n",
    "topic_diff['33'] = all_split_df.iloc[:,33]-all_split_df.iloc[:,133]\n",
    "topic_diff['34'] = all_split_df.iloc[:,34]-all_split_df.iloc[:,134]\n",
    "topic_diff['35'] = all_split_df.iloc[:,35]-all_split_df.iloc[:,135]\n",
    "topic_diff['36'] = all_split_df.iloc[:,36]-all_split_df.iloc[:,136]\n",
    "topic_diff['37'] = all_split_df.iloc[:,37]-all_split_df.iloc[:,137]\n",
    "topic_diff['38'] = all_split_df.iloc[:,38]-all_split_df.iloc[:,138]\n",
    "topic_diff['39'] = all_split_df.iloc[:,39]-all_split_df.iloc[:,139]\n",
    "topic_diff['40'] = all_split_df.iloc[:,40]-all_split_df.iloc[:,140]\n",
    "topic_diff['41'] = all_split_df.iloc[:,41]-all_split_df.iloc[:,141]\n",
    "topic_diff['42'] = all_split_df.iloc[:,42]-all_split_df.iloc[:,142]\n",
    "topic_diff['43'] = all_split_df.iloc[:,43]-all_split_df.iloc[:,143]\n",
    "topic_diff['44'] = all_split_df.iloc[:,44]-all_split_df.iloc[:,144]\n",
    "topic_diff['45'] = all_split_df.iloc[:,45]-all_split_df.iloc[:,145]\n",
    "topic_diff['46'] = all_split_df.iloc[:,46]-all_split_df.iloc[:,146]\n",
    "topic_diff['47'] = all_split_df.iloc[:,47]-all_split_df.iloc[:,147]\n",
    "topic_diff['48'] = all_split_df.iloc[:,48]-all_split_df.iloc[:,148]\n",
    "topic_diff['49'] = all_split_df.iloc[:,49]-all_split_df.iloc[:,149]\n",
    "topic_diff['50'] = all_split_df.iloc[:,50]-all_split_df.iloc[:,150]\n",
    "topic_diff['51'] = all_split_df.iloc[:,51]-all_split_df.iloc[:,151]\n",
    "topic_diff['52'] = all_split_df.iloc[:,52]-all_split_df.iloc[:,152]\n",
    "topic_diff['53'] = all_split_df.iloc[:,53]-all_split_df.iloc[:,153]\n",
    "topic_diff['54'] = all_split_df.iloc[:,54]-all_split_df.iloc[:,154]\n",
    "topic_diff['55'] = all_split_df.iloc[:,55]-all_split_df.iloc[:,155]\n",
    "topic_diff['56'] = all_split_df.iloc[:,56]-all_split_df.iloc[:,156]\n",
    "topic_diff['57'] = all_split_df.iloc[:,57]-all_split_df.iloc[:,157]\n",
    "topic_diff['58'] = all_split_df.iloc[:,58]-all_split_df.iloc[:,158]\n",
    "topic_diff['59'] = all_split_df.iloc[:,59]-all_split_df.iloc[:,159]\n",
    "topic_diff['60'] = all_split_df.iloc[:,60]-all_split_df.iloc[:,160]\n",
    "topic_diff['61'] = all_split_df.iloc[:,61]-all_split_df.iloc[:,161]\n",
    "topic_diff['62'] = all_split_df.iloc[:,62]-all_split_df.iloc[:,162]\n",
    "topic_diff['63'] = all_split_df.iloc[:,63]-all_split_df.iloc[:,163]\n",
    "topic_diff['64'] = all_split_df.iloc[:,64]-all_split_df.iloc[:,164]\n",
    "topic_diff['65'] = all_split_df.iloc[:,65]-all_split_df.iloc[:,165]\n",
    "topic_diff['66'] = all_split_df.iloc[:,66]-all_split_df.iloc[:,166]\n",
    "topic_diff['67'] = all_split_df.iloc[:,67]-all_split_df.iloc[:,167]\n",
    "topic_diff['68'] = all_split_df.iloc[:,68]-all_split_df.iloc[:,168]\n",
    "topic_diff['69'] = all_split_df.iloc[:,69]-all_split_df.iloc[:,169]\n",
    "topic_diff['70'] = all_split_df.iloc[:,70]-all_split_df.iloc[:,170]\n",
    "topic_diff['71'] = all_split_df.iloc[:,71]-all_split_df.iloc[:,171]\n",
    "topic_diff['72'] = all_split_df.iloc[:,72]-all_split_df.iloc[:,172]\n",
    "topic_diff['73'] = all_split_df.iloc[:,73]-all_split_df.iloc[:,173]\n",
    "topic_diff['74'] = all_split_df.iloc[:,74]-all_split_df.iloc[:,174]\n",
    "topic_diff['75'] = all_split_df.iloc[:,75]-all_split_df.iloc[:,175]\n",
    "topic_diff['76'] = all_split_df.iloc[:,76]-all_split_df.iloc[:,176]\n",
    "topic_diff['77'] = all_split_df.iloc[:,77]-all_split_df.iloc[:,177]\n",
    "topic_diff['78'] = all_split_df.iloc[:,78]-all_split_df.iloc[:,178]\n",
    "topic_diff['79'] = all_split_df.iloc[:,79]-all_split_df.iloc[:,179]\n",
    "topic_diff['80'] = all_split_df.iloc[:,80]-all_split_df.iloc[:,180]\n",
    "topic_diff['81'] = all_split_df.iloc[:,81]-all_split_df.iloc[:,181]\n",
    "topic_diff['82'] = all_split_df.iloc[:,82]-all_split_df.iloc[:,182]\n",
    "topic_diff['83'] = all_split_df.iloc[:,83]-all_split_df.iloc[:,183]\n",
    "topic_diff['84'] = all_split_df.iloc[:,84]-all_split_df.iloc[:,184]\n",
    "topic_diff['85'] = all_split_df.iloc[:,85]-all_split_df.iloc[:,185]\n",
    "topic_diff['86'] = all_split_df.iloc[:,86]-all_split_df.iloc[:,186]\n",
    "topic_diff['87'] = all_split_df.iloc[:,87]-all_split_df.iloc[:,187]\n",
    "topic_diff['88'] = all_split_df.iloc[:,88]-all_split_df.iloc[:,188]\n",
    "topic_diff['89'] = all_split_df.iloc[:,89]-all_split_df.iloc[:,189]\n",
    "topic_diff['90'] = all_split_df.iloc[:,90]-all_split_df.iloc[:,190]\n",
    "topic_diff['91'] = all_split_df.iloc[:,91]-all_split_df.iloc[:,191]\n",
    "topic_diff['92'] = all_split_df.iloc[:,92]-all_split_df.iloc[:,192]\n",
    "topic_diff['93'] = all_split_df.iloc[:,93]-all_split_df.iloc[:,193]\n",
    "topic_diff['94'] = all_split_df.iloc[:,94]-all_split_df.iloc[:,194]\n",
    "topic_diff['95'] = all_split_df.iloc[:,95]-all_split_df.iloc[:,195]\n",
    "topic_diff['96'] = all_split_df.iloc[:,96]-all_split_df.iloc[:,196]\n",
    "topic_diff['97'] = all_split_df.iloc[:,97]-all_split_df.iloc[:,197]\n",
    "topic_diff['98'] = all_split_df.iloc[:,98]-all_split_df.iloc[:,198]\n",
    "topic_diff['99'] = all_split_df.iloc[:,99]-all_split_df.iloc[:,199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_diff['label'] = all_split_df['label']\n",
    "topic_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_diff['10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = topic_diff.loc[:,topic_diff.columns != 'label']\n",
    "y = topic_diff['label'] # Target variable\n",
    "    # split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "    # instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "    # fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "    # predict y\n",
    "y_pred=logreg.predict(X_test)\n",
    "#     Add results for training set\n",
    "get_results(cnf_matrix)\n",
    "y_pred_train=logreg.predict(X_train)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix_train = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "results_diff = get_results(cnf_matrix)\n",
    "results_train_diff = get_results(cnf_matrix_train)\n",
    "print(results_diff)\n",
    "print(results_train_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_topics.mean(axis=0,index ='label')\n",
    "mean_topic_diff = topic_diff.groupby('label').mean()\n",
    "mean_topic_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.DataFrame()\n",
    "df_test = [1,2,3,4,5,6,7]\n",
    "\n",
    "df_test_df = pd.DataFrame (df_test)\n",
    "rand = df_test_df.sample(frac = 1).reset_index(drop=True)\n",
    "print(rand)\n",
    "print(pd.concat([df_test_df, rand], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_topic_diff_T = mean_topic_diff.T\n",
    "mean_topic_diff_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= range(0,len(mean_topic_diff_T[0]))\n",
    "\n",
    "y1 = mean_topic_diff_T[0]\n",
    "y2 = mean_topic_diff_T[1]\n",
    "plt.plot(x, y1, label = \"line 1\")\n",
    "plt.plot(x, y2, label = \"line 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_topic_diff['9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_topics = create_topics(dm_ln,'articles')\n",
    "good_topics['label'] = 1\n",
    "print(\"good topics created\")\n",
    "dm_split = split_articles(dm_ln,'articles')\n",
    "print(\"split articles\")\n",
    "# Create bad articles by randomising second half\n",
    "bad_df =  pd.DataFrame()\n",
    "bad_df['part1'] = dm_split['part1']\n",
    "bad_df['part2'] = np.random.permutation(dm_split['part2'].values)\n",
    "# and merge\n",
    "bad_df['all'] = bad_df.part1.str.cat(bad_df.part2)\n",
    "bad_topics = create_topics(bad_df,'all')\n",
    "bad_topics['label'] = 0\n",
    "print(\"bad topics created\")\n",
    "# Dataset with good and bad articles\n",
    "final_topics = good_topics.append(bad_topics)\n",
    "print(\"final topics merged\")\n",
    "# Create NF Model\n",
    "X = final_topics.loc[:,final_topics.columns != 'label']\n",
    "y = final_topics['label'] # Target variable\n",
    "# split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "print(\"NF model set up\")\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "print(\"NF model trained\")\n",
    "# predict y\n",
    "y_pred=logreg.predict(X_test)\n",
    "y_train_pred=logreg.predict(X_train)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results(cnf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view words only\n",
    "# topics_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view count of words\n",
    "# my_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words.extend(['come', 'first', 'last', 'like', 'new', 'take', 'tell', 'two', 'would', 'show'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix_train = metrics.confusion_matrix(y_train, y_train_pred)\n",
    "cnf_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results(cnf_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_results = X_test\n",
    "Test_results['y_pred'] = y_pred\n",
    "Test_results['y_test'] = y_test\n",
    "# Test_results.to_csv('Test_results.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_results.loc[:,'y_pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for same code, same random seed\n",
    "# 0.5537206139498737 / 0.5620749951428017 / 0.5478919759082961\n",
    "# 0.5558937823834197 / 0.5531735751295337 / 0.551619170984456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_df_pt1 = create_topics(dm_split,'part1')\n",
    "# good_df_pt2 = create_topics(dm_split,'part2')\n",
    "# good_df_all = pd.concat([good_df_pt1, good_df_pt2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge\n",
    "# bad_df_all = pd.concat([bad_df_pt1, bad_df_pt2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
